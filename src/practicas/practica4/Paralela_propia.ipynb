{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Iniciar random\n",
    "np.random.seed(6)\n",
    "\n",
    "# Variables globales con información para acelerar procesamiento\n",
    "g_filas = g_cols = 0    # Serán números (1.000.000 y 11 en este caso)\n",
    "\n",
    "ITER = 10\n",
    "APRN = 0.5\n",
    "LMBD = 0.000002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linea es un string de la forma:\n",
    "# \"n0, n1, n2, ..., n10, r\" donde nX es una propiedad del tráfico y r es\n",
    "# su clasificación (1 si es botnet, 0 si no lo es)\n",
    "def formato_inicial(linea):\n",
    "    aux   = [float(i) for i in linea.split(',')]\n",
    "    datos = np.array(aux[:-1])\n",
    "    resul = aux[-1]\n",
    "    return (datos, resul)\n",
    "\n",
    "# Devuelve un RDD de los datos del fichero fn.\n",
    "# Cada registro del RDD es una tupla (X, y)\n",
    "#  X: np.array de los datos\n",
    "#  y: clasificación (1 = botnet, 0 = no botnet)\n",
    "def readFile(fn):\n",
    "    global g_filas, g_cols\n",
    "    sc      = SparkContext(\"local[*]\", \"BotnetParalelaPruebas\")\n",
    "    todo    = sc.textFile(fn)\n",
    "    ret     = todo.map(formato_inicial)\n",
    "    g_filas = todo.count()\n",
    "    g_cols  = len(ret.take(1)[0][0])\n",
    "    return ret\n",
    "\n",
    "t1  = time.time()\n",
    "rdd = readFile(\"../../../datos/botnet_tot_syn_l.csv\")\n",
    "t2  = time.time()\n",
    "print(\"Tiempo transcurrido: {} segundos.\".format(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd: RDD de 1.000.000 de registros (X, y)\n",
    "#  X es un array con 11 flotantes\n",
    "#  y es 1 ó 0\n",
    "# Devuelve un np.array con las medias de las 11 columnas\n",
    "def calcular_medias(rdd):\n",
    "    global g_filas\n",
    "    medias = np.array(rdd.reduce(lambda x, y: x + y)[0])/g_filas\n",
    "    return medias\n",
    "\n",
    "# rdd: RDD de 1.000.000 de registros (X, y)\n",
    "#  X es un array con 11 flotantes\n",
    "#  y es 1 ó 0\n",
    "# medias: np.array de las medias de las 11 columnas\n",
    "def calcular_stdev(rdd, medias):\n",
    "    global g_filas\n",
    "    parcial  = np.array(rdd.map(lambda x: (x[0]-medias)**2).reduce(lambda x, y: x + y))\n",
    "    varianza = parcial/g_filas\n",
    "    stdev    = np.sqrt(varianza)\n",
    "    return stdev\n",
    "\n",
    "# Toma por parámetro un RDD de 1.000.000 de registros.\n",
    "# Cada registro tiene la forma (X, y)\n",
    "# X es un array con 11 flotantes\n",
    "# y es 1 ó 0\n",
    "# Devuelve un RDD equivalente donde la X de cada tupla está\n",
    "# reescalada a N(0, 1) (media = 0, desv. est. = 1)\n",
    "def normalizar(rdd):\n",
    "    global g_filas\n",
    "    t1 = time.time()\n",
    "    medias = calcular_medias(rdd)\n",
    "    t2 = time.time()\n",
    "    stdevs = calcular_stdev(rdd, medias)\n",
    "    t3 = time.time()\n",
    "    normal = rdd.map(lambda x: ((x[0] - medias)/stdevs, x[1]))\n",
    "    t4 = time.time()\n",
    "    print(\"Tiempo medias: {} s.\".format(t2 - t1))\n",
    "    print(\"Tiempo stdevs: {} s.\".format(t3 - t2))\n",
    "    print(\"Tiempo normal: {} s.\".format(t4 - t3))\n",
    "    return normal\n",
    "    \n",
    "\n",
    "t1 = time.time()\n",
    "datos = normalizar(rdd)\n",
    "t2 = time.time()\n",
    "print(\"Tiempo transcurrido: {} segundos.\".format(t2 - t1))\n",
    "# La media tiene que ser ~0\n",
    "# La desviación estándar tiene que ser ~1\n",
    "\n",
    "# 1.2345e-05 = 0.000012345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fila: np.array de 11 flotantes\n",
    "# salida: predicción para esos 11 flotantes. ŷ.\n",
    "def sigm(fila, pesos, sesgo):\n",
    "    entrada = np.sum(fila * pesos) + sesgo\n",
    "    salida  = 1 / (1 + np.exp(-entrada))\n",
    "    return salida\n",
    "\n",
    "# Calcula las derivadas para cada fila de datos\n",
    "# Luego hace la media sumando las filas y dividiendo entre el nº\n",
    "#  parciales: RDD de 1M de registros cada una con 11 derivadas parciales\n",
    "#  derivadas: array de 11 derivadas totales hechos con las medias del millón de parciales\n",
    "def drv_pesos(datos, pesos, sesgo):\n",
    "    global g_filas\n",
    "    parciales = datos.map(lambda x: x[0] * (sigm(x[0], pesos, sesgo)) - x[1])\n",
    "    derivadas = (parciales.reduce(lambda x, y: x + y))/g_filas\n",
    "    return derivadas\n",
    "\n",
    "def drv_sesgo(datos, pesos, sesgo):\n",
    "    global g_filas\n",
    "    parciales = datos.map(lambda x: sigm(x[0], pesos, sesgo) - x[1])\n",
    "    derivadas = (parciales.reduce(lambda x, y: x + y))/g_filas\n",
    "    return derivadas\n",
    "\n",
    "def presio(datos, pesos, sesgo):\n",
    "    global g_filas\n",
    "    inter = rdd.map(lambda x: (x[1]*np.log(sigm(x[0], pesos, sesgo)))+((1-x[1])*np.log(1-sigm(x[0], pesos, sesgo))))\n",
    "    suma  = inter.reduce(lambda x, y: x + y)\n",
    "    coste = -(1/g_filas) * suma\n",
    "    return coste\n",
    "\n",
    "# datos: RDD de 1M de tuplas (X, y). X es un np.array de 11 flotantes. Normalizados.\n",
    "def entrenar(datos, iteraciones, aprendizaje):\n",
    "    global g_filas, g_cols\n",
    "    pesos  = np.zeros([g_cols, ])\n",
    "    sesgo  = 0\n",
    "    dpesos = np.zeros([g_cols, ])\n",
    "    dsesgo = 0\n",
    "    \n",
    "    for it in range(iteraciones):\n",
    "        t1 = time.time()\n",
    "        dpesos = drv_pesos(datos, pesos, sesgo)\n",
    "        dsesgo = drv_sesgo(datos, pesos, sesgo)\n",
    "        \n",
    "        pesos  = pesos - dpesos * aprendizaje\n",
    "        sesgo  = sesgo - dsesgo * aprendizaje\n",
    "        \n",
    "        coste = presio(datos, pesos, sesgo)\n",
    "        t2 = time.time()\n",
    "        print(str(it) + \": \" + str(coste) + \" [{}]\".format(t2 - t1))\n",
    "    return pesos, sesgo\n",
    "\n",
    "t1 = time.time()\n",
    "PESOS, SESGO = entrenar(datos, ITER, APRN)\n",
    "t2 = time.time()\n",
    "print(\"Tiempo transcurrido: {} segundos.\".format(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(datos, pesos, sesgo):\n",
    "    global g_filas\n",
    "    paso1 = datos.map(lambda x: (sigm(x[0], pesos, sesgo), x[1]))\n",
    "    paso2 = paso1.map(lambda x: (np.rint(x[0]) == x[1], 1))\n",
    "    preds = paso2.reduceByKey(lambda x, y: x + y)\n",
    "    \n",
    "    preci = preds.collectAsMap()[True]/g_filas\n",
    "    return preci\n",
    "\n",
    "t1 = time.time()\n",
    "precision_ = precision(datos, PESOS, SESGO)\n",
    "t2 = time.time()\n",
    "print(\"La precisión es: {} [{}]\".format(precision_, (t2 - t1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
